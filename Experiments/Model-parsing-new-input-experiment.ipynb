{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "class Predictor():\n",
    "\n",
    "    def __init__(self):\n",
    "        self._load()\n",
    "        self._load_tokenizer()\n",
    "\n",
    "\n",
    "    def _load(self):\n",
    "        '''\n",
    "        initalize the model with a predefined architecture\n",
    "        and weights\n",
    "        '''\n",
    "        try:\n",
    "            json_file = open('../model/weights/model.json', 'r')\n",
    "            loaded_model_json = json_file.read()\n",
    "            json_file.close()\n",
    "            loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "            loaded_model.load_weights(\"../model/weights/model_weights.h5\")\n",
    "            self.model=loaded_model\n",
    "        except:\n",
    "            print('Loading backup weights')\n",
    "            self._load_backup()\n",
    "                \n",
    "\n",
    "    def _load_tokenizer(self):\n",
    "        with open('tokenizer.pickle', 'rb') as handle:\n",
    "            self.tokenizer = pickle.load(handle)\n",
    "\n",
    "\n",
    "\n",
    "    def _load_backup(self):\n",
    "        ''' \n",
    "        These are backu weights! We might update them once everything is over.\n",
    "        But they do not perform to well\n",
    "        '''\n",
    "\n",
    "        #Create an instance of the model architecture\n",
    "        json_file = open('../model/weights/model.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "                \n",
    "\n",
    "        #load specific weights from np array\n",
    "        embedded = np.load('weights/backup/embedded_weights.npy')\n",
    "        lstm_weights = np.load('weights/backup/LSTM_weights.npy', allow_pickle=True)\n",
    "        dense_weights = np.load('weights/backup/dense_weights.npy',allow_pickle=True)\n",
    "        out_weights = np.load('weights//backupout_weights.npy',allow_pickle=True)\n",
    "\n",
    "        #manually put the weights in their place\n",
    "        loaded_model.layers[0].set_weights(embedded)\n",
    "        loaded_model.layers[1].set_weights(lstm_weights)\n",
    "        loaded_model.layers[4].set_weights(dense_weights)\n",
    "        loaded_model.layers[6].set_weights(out_weights)\n",
    "        \n",
    "        self.model = loaded_model\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def update_weights(path_to_weights):\n",
    "        '''\n",
    "        Update the weights of an existing architecture\n",
    "        If we have trained the current architecture and got better\n",
    "        results, etc.\n",
    "        input: path to the weights respectively from the folder\n",
    "                of this instance\n",
    "        return True if succeded or false if it failed\n",
    "        '''\n",
    "        try:\n",
    "            self.model.load_weights(path_to_weights)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def update_model(path_to_model, path_to_weights):\n",
    "        '''\n",
    "        Update the whole model with new weights.\n",
    "        Can be used if we have an instance of the model running\n",
    "        and want to deploy a new architecture\n",
    "        input: path to the model.json and weights.h5 for the new arch\n",
    "                They need to be respectively to the model place\n",
    "        return True if secceded and False if failed\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            json_file = open(path_to_model, 'r')\n",
    "            loaded_model_json = json_file.read()\n",
    "            json_file.close()\n",
    "            loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "            loaded_model.load_weights(path_to_weights)\n",
    "            self.model=loaded_model\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def analyze(self,to_test):\n",
    "        '''\n",
    "        Use the model to analyze a text string and try to \n",
    "        find if it is fake or not\n",
    "        input: text string\n",
    "        return: prediction of the model\n",
    "        '''\n",
    "        \n",
    "        tokenized = self.tokenizer.texts_to_sequences(texts=to_test)\n",
    "        model_input = pad_sequences(tokenized, maxlen=1000)\n",
    "        \n",
    "\n",
    "        acc = self.model.predict(model_input)\n",
    "        print(acc)\n",
    "        #return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4332623  0.56862617]\n",
      " [0.40020674 0.6015738 ]\n",
      " [0.41427055 0.5967328 ]\n",
      " [0.41818455 0.5846902 ]\n",
      " [0.41589504 0.59310514]\n",
      " [0.42396784 0.592606  ]\n",
      " [0.40375432 0.5973142 ]\n",
      " [0.41413182 0.5940359 ]\n",
      " [0.42396784 0.592606  ]\n",
      " [0.41818455 0.5846902 ]\n",
      " [0.4110927  0.6024736 ]\n",
      " [0.41413182 0.5940359 ]\n",
      " [0.42396784 0.592606  ]\n",
      " [0.4160996  0.5909224 ]\n",
      " [0.40020674 0.6015738 ]\n",
      " [0.40020674 0.6015738 ]\n",
      " [0.4093267  0.5998951 ]]\n"
     ]
    }
   ],
   "source": [
    "pre.analyze('Today we are cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
